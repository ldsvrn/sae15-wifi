{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d3acae",
   "metadata": {},
   "source": [
    "# Projet Wi-fi UHA\n",
    "\n",
    "## Sujet:\n",
    "\n",
    "### Synopsis\n",
    "Le projet Wi-Fi UHA consiste à analyser les données relatives à l'enregistrement de la puissance du signal Wi-Fi généré par les points d'accès dans le bâtiment C. \n",
    "\n",
    "### Données\n",
    "Les données obtenus à partir du Fipy Pycomm et ont été sauvegardées dans le dossier *data/raw*. Il contient deux dossiers l'un relatif à une série de mesures effectuées au rez-de-chaussée du bâtiment C, l'autre à une série de mesure au premier étage du bâtiment C. \n",
    "\n",
    "### Tâches\n",
    "Les tâches demandées dans ce projet sont les suivantes.\n",
    "\n",
    "1. Compléter le programme src/data/extract-data.py afin de formater le jeux de données dans un fichier csv.\n",
    "2. Écrire un programme qui fusionne deux fichiers csv.\n",
    "3. Établir pour chaque variable le nombre de valeurs manquantes et aberrante ainsi que le pourcentage que cela représente.\n",
    "4. Établir le nombre et le pourcentage d'observations qui ont des valeurs aberrantes et/ou manquantes.\n",
    "5. Définir les fonctions ComputeMean et ComputeMedian (*src/model/model.py*) et calculer la moyenne et la médiane de la puissance du signal Wi-Fi du réseau UHA à chaque emplacement où les mesures ont été effectuées.\n",
    "6. Afficher la heatmap de la puissance du signal Wi-Fi du réseau UHA en fonction des positions où les mesures ont été effectués"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c455c",
   "metadata": {},
   "source": [
    "\n",
    "## Installation:\n",
    "**Cloner le repo:**\n",
    "\n",
    "avec SSH:\n",
    "```bash\n",
    "git clone git@github.com:ldsvrn/sae15-wifi.git\n",
    "```\n",
    "ou en https:\n",
    "```bash\n",
    "git clone https://github.com/ldsvrn/sae15-wifi\n",
    "```\n",
    "\n",
    "**Créer l'environnement virtuel:**\n",
    "```bash\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip3 install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Lancement de Jupyter:**\n",
    "```bash\n",
    ".venv/bin/jupyter-notebook\n",
    "```\n",
    "\n",
    "**Mise à jour du fichier requirements.txt si nécessaire:**\n",
    "```bash\n",
    "pip3 freeze > requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85456f41",
   "metadata": {},
   "source": [
    "## Utilisation:\n",
    "### Parser pour extraire les données brutes:\n",
    "```bash\n",
    "src/data/extract-data.py -i *path raw dataset* -o *csv output path*\n",
    "```\n",
    "**Code source du script:**\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "def ExtractFolderName(path):\n",
    "    return os.path.dirname(path)\n",
    "\n",
    "\n",
    "def ExtractFileName(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "\n",
    "def ExtractPlace(folderName):\n",
    "    return folderName.split(\"-\")[1]\n",
    "\n",
    "\n",
    "def ExtractDate(folderName):\n",
    "    temp = folderName.split(\"-\")[2]\n",
    "    return f\"{temp.split('_')[2]}-{temp.split('_')[1]}-{temp.split('_')[0]}\" # ISO8601 date format\n",
    "\n",
    "\n",
    "def ExtractIdExp(fileName):\n",
    "    return fileName.split(\"-\")[-1]\n",
    "\n",
    "\n",
    "def ExtractSsid(content):\n",
    "    return content.split(\"'\")[0][:-1]\n",
    "\n",
    "\n",
    "def ExtractMacAddr(content):\n",
    "    return content.split(\"'\")[1]\n",
    "\n",
    "\n",
    "def ExtractRssi(content):\n",
    "    return content.split(\"'\")[2]\n",
    "\n",
    "\n",
    "def ExtractInfo(path):\n",
    "    folderName = ExtractFolderName(path)  # Extract folder name\n",
    "    fileName = ExtractFileName(path)  # Extract filename\n",
    "    result = \"\"\n",
    "    descRd = None\n",
    "    descRd = open(path, \"r\")\n",
    "    content = descRd.readlines()\n",
    "    for idx in content:\n",
    "        result += f\"{ExtractPlace(folderName)},{ExtractDate(folderName)},{ExtractIdExp(fileName)},\" \\\n",
    "                  f\"{ExtractSsid(idx)},{ExtractMacAddr(idx)},{ExtractRssi(idx)}\"\n",
    "    descRd.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # declare variables\n",
    "    isFileCreated = False\n",
    "    descWr = None\n",
    "    result = \"\"\n",
    "    folderName = \"\"\n",
    "    fileName = \"\"\n",
    "\n",
    "    # define arguments\n",
    "    parser = argparse.ArgumentParser(description='Extract information from Wi-Fi logs')\n",
    "    parser.add_argument(\"-i\", help=\"path of the input file\", required=True)\n",
    "    parser.add_argument(\"-o\", help=\"path of the output file\", default=\"../../data/processed/wifi.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if os.path.isfile(args.i):\n",
    "        result = ExtractInfo(args.i)\n",
    "        descWr = open(args.o, \"w\")\n",
    "        descWr.write(\"Location,Date,ExpId,SSID,Addr,RSSI\\n\")\n",
    "        descWr.write(result)\n",
    "        descWr.close()\n",
    "    elif os.path.isdir(args.i):\n",
    "        listFiles = os.listdir(args.i)\n",
    "        for fichier in listFiles:\n",
    "            if isFileCreated == False:\n",
    "                descWr = open(args.o, \"w\")\n",
    "                descWr.write(\"Building,Date,ExpId,SSID,Addr,RSSI\\n\")\n",
    "                descWr.close()\n",
    "                isFileCreated = True\n",
    "            result = ExtractInfo(args.i + fichier)\n",
    "            descWr = open(args.o, \"a\")\n",
    "            descWr.write(result)\n",
    "            descWr.close()\n",
    "            result = \"\"\n",
    "    else:\n",
    "        print(\"Erreur : le fichier ou le dossier n'existe pas\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e1097",
   "metadata": {},
   "source": [
    "\n",
    "### Script pour fusionner les csv et trier par ExpId:\n",
    "```bash\n",
    "src/data/merge-csv.py -i *csv dataset folder* -o *merged csv*\n",
    "```\n",
    "**Code source:**\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Merge and sort csv')\n",
    "    parser.add_argument(\"-i\", help=\"path of the input folder\", required=True)\n",
    "    parser.add_argument(\"-o\", help=\"path of the output file\", default=\"wifi-merged.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    files = glob(os.path.join(args.i, \"wifi*.csv\"))\n",
    "    print(files)\n",
    "\n",
    "    df = pd.concat(map(pd.read_csv, files), ignore_index=True).sort_values(by=[\"ExpId\"], ascending=True)\n",
    "    df.to_csv(args.o, index=False)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25f3bf",
   "metadata": {},
   "source": [
    "### Nettoyage et tri des données\n",
    "\n",
    "On commence par importer la library clean (le fichier est simlink de scr/data/clean.py à notebook/clean.py pour être importé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2780d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9e06a",
   "metadata": {},
   "source": [
    "Ensuite, on crée l'objet en précisant l'emplacement du csv, le réseau que l'on souhaite analyser et éventuellement supprimer les doublons.\n",
    "\n",
    "On peut ensuite lancer le nettoyage et le tri avec la méthode `clean()`.\n",
    "\n",
    "**Code source de la méthode clean()**\n",
    "```python\n",
    "    def clean(self):\n",
    "        # if null value, delete the row\n",
    "        temp = len(self.df)\n",
    "        self.df.dropna(inplace=True)\n",
    "        self.deleted_null = temp - len(self.df)\n",
    "\n",
    "        # delete all duplicates\n",
    "        temp = len(self.df)\n",
    "        if self.drop_duplicates:\n",
    "            self.df.drop_duplicates(inplace=True)\n",
    "        self.deleted_duplicates = temp - len(self.df)\n",
    "\n",
    "        temp = len(self.df)\n",
    "        self.df = self.df.loc[(self.df[\"RSSI\"] <= -10) & (self.df[\"RSSI\"] >= -100)]\n",
    "        self.deleted_RSSI = temp - len(self.df)\n",
    "\n",
    "        temp = len(self.df)\n",
    "        self.df = self.df.loc[self.df[\"SSID\"] == self.networks]\n",
    "        self.deleted_SSID = temp - len(self.df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ad8ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: uha\n"
     ]
    }
   ],
   "source": [
    "cleaner = clean.Cleaner(\"../data/processed/wifi-merged.csv\", \"uha\")\n",
    "\n",
    "# On récupère le nombres de lignes avant de nettoyer\n",
    "totalLines = cleaner.get_lines()\n",
    "\n",
    "# On peut nettoyer et trier:\n",
    "cleaner.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12f8cd",
   "metadata": {},
   "source": [
    "Grâce à la méthode `get_delete_reason()`, on récupère un dictonnaire décrivant combien de lignes ont été supprimées pour chaque raison.\n",
    "\n",
    "**Code source de get_delete_reason():**\n",
    "```python\n",
    "    def get_delete_reason(self):\n",
    "        if self.drop_duplicates:\n",
    "            return {\n",
    "                \"null\": self.deleted_null,\n",
    "                \"RSSI\": self.deleted_RSSI,\n",
    "                \"duplicates\": self.deleted_duplicates,\n",
    "                \"SSID\": self.deleted_SSID\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"null\": self.deleted_null,\n",
    "                \"RSSI\": self.deleted_RSSI,\n",
    "                \"SSID\": self.deleted_SSID\n",
    "            }\n",
    "```\n",
    "\n",
    "- **\"null\"** pour les lignes comportant une cellule vide\n",
    "- **\"duplicates\"** pour le lignes doublons (seulement si la suppression est activée)\n",
    "- **\"RSSI\"** pour les valeurs de RSSI aberrantes (pas entre -100 et -10, les limites du 802.11)\n",
    "- **\"SSID\"** pour les valeurs d'autres réseaux que ceux précisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ae42ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaner.get_delete_reason()\n",
    "\n",
    "# On la stocke dans une variable pour réutiliser les données facilement\n",
    "delete_reason = cleaner.get_delete_reason()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88b228",
   "metadata": {},
   "source": [
    "On peut donc écrire un petit algorithme pour afficher ces données. *(ici on utilise pas de graphique matplotlib car les valeurs sont trop eloignées pour être visibles correctement)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396634d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parmis les 4147 valeurs supprimées:\n",
      "- 1 on été supprimés pour null (soit 0.024%)\n",
      "- 4 on été supprimés pour RSSI (soit 0.096%)\n",
      "- 4142 on été supprimés pour SSID (soit 99.879%)\n"
     ]
    }
   ],
   "source": [
    "total_deleted= cleaner.get_total_deleted()\n",
    "\n",
    "print(f\"Parmis les {total_deleted} valeurs supprimées:\")\n",
    "for i in delete_reason:\n",
    "    print(f\"- {delete_reason[i]} on été supprimés pour {i} (soit {round(delete_reason[i]/total_deleted*100, 3)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea14c0",
   "metadata": {},
   "source": [
    "Après avoir trié ces données, nous pouvons les exporter grâce à la méthode `to_csv()`\n",
    "```python\n",
    "   def to_csv(self, output_path):\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42fb8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.to_csv(\"../data/cleaned/wifi-uha.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754d353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
